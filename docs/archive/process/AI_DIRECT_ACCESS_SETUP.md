# ðŸš€ AI Direct Access Setup Guide
## Making ChatGPT Directly Control Your Infrastructure

**Created**: 6 November 2025  
**Purpose**: Enable AI assistants to directly SSH, access Google Sheets, and modify BigQuery  
**Status**: âš ï¸ POWERFUL - Use with caution!

---

## âš ï¸ Important Warning

This guide shows how to give AI assistants **direct access** to your infrastructure. This is:

âœ… **Extremely powerful** - AI can do everything automatically  
âš ï¸ **Requires trust** - AI will have full access to your systems  
ðŸ”’ **Needs security** - Proper authentication and rate limiting required  
ðŸ’° **Has costs** - AI operations may trigger cloud spending  

**Recommended approach**: Start with read-only access, then gradually enable write access.

---

## ðŸŽ¯ What We'll Set Up

### **Level 1: Read-Only Access** (Safe)
- âœ… ChatGPT can query BigQuery
- âœ… ChatGPT can read Google Sheets
- âœ… ChatGPT can check UpCloud server status
- âŒ Cannot modify data
- âŒ Cannot run destructive commands

### **Level 2: Monitored Write Access** (Moderate Risk)
- âœ… ChatGPT can update Google Sheets
- âœ… ChatGPT can run approved scripts
- âœ… All actions logged and notified
- âš ï¸ Limited to specific operations

### **Level 3: Full Automation** (High Risk/High Reward)
- âœ… ChatGPT can deploy code
- âœ… ChatGPT can modify BigQuery
- âœ… ChatGPT can SSH into servers
- âš ï¸ Requires approval workflow
- ðŸ”’ Strong security required

---

## ðŸ—ï¸ Architecture: ChatGPT â†’ Your Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    ChatGPT     â”‚
â”‚   (OpenAI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ HTTPS (API calls)
        â”‚ Authentication: API Key
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI Middleware Server    â”‚
â”‚   (Your Mac or UpCloud)        â”‚
â”‚                                â”‚
â”‚   â€¢ Authentication             â”‚
â”‚   â€¢ Rate limiting              â”‚
â”‚   â€¢ Logging                    â”‚
â”‚   â€¢ Approval workflow          â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        â”‚        â”‚
    â”‚        â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        â”‚                      â”‚
    â–¼        â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚BigQuery â”‚ â”‚Google Sheets â”‚  â”‚ UpCloud  â”‚
â”‚         â”‚ â”‚              â”‚  â”‚  Server  â”‚
â”‚ Read/   â”‚ â”‚ Read/Write   â”‚  â”‚   SSH    â”‚
â”‚ Write   â”‚ â”‚   via API    â”‚  â”‚ Execute  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“‹ Prerequisites

### **Required**:
1. âœ… UpCloud server (94.237.55.15) - already running
2. âœ… Service account credentials - already configured
3. âœ… Google Sheets API enabled - already working
4. âœ… BigQuery access - already working
5. âš ï¸ OpenAI API key (for ChatGPT Actions)
6. âš ï¸ FastAPI server (we'll create this)

### **Optional**:
- SSL certificate (for HTTPS)
- Domain name (for production)
- Monitoring/alerting (Slack, email)

---

## ðŸ”§ Setup Steps

## **Step 1: Create FastAPI Middleware Server**

This server sits between ChatGPT and your infrastructure, handling authentication and executing commands.

### **1.1: Create the API Server**

```python
# File: api_gateway.py
from fastapi import FastAPI, HTTPException, Header, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from google.cloud import bigquery
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import paramiko
import os
from typing import Optional
from datetime import datetime
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Power Market AI Gateway")
security = HTTPBearer()

# Configuration
UPCLOUD_HOST = "94.237.55.15"
UPCLOUD_USER = "root"
UPCLOUD_KEY_PATH = os.path.expanduser("~/.ssh/id_rsa")
BQ_PROJECT = "inner-cinema-476211-u9"
BQ_DATASET = "uk_energy_prod"
SHEETS_ID = "1-u794iGngn5_Ql_XocKSwvHSKWABWO0bVsudkUJAFqA"

# API Key validation (replace with your secure key)
VALID_API_KEY = os.environ.get("AI_GATEWAY_API_KEY", "your-secure-api-key-here")

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Verify API key from Bearer token"""
    if credentials.credentials != VALID_API_KEY:
        logger.warning(f"Invalid API key attempt: {credentials.credentials[:10]}...")
        raise HTTPException(status_code=403, detail="Invalid API key")
    return credentials.credentials

# Initialize clients
bq_client = bigquery.Client(project=BQ_PROJECT)

def get_sheets_client():
    """Get authenticated Google Sheets client"""
    scope = ['https://spreadsheets.google.com/feeds',
             'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name(
        'inner-cinema-credentials.json', scope)
    return gspread.authorize(creds)

# ============================================
# LEVEL 1: READ-ONLY ENDPOINTS (SAFE)
# ============================================

@app.get("/")
def root():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Power Market AI Gateway",
        "version": "1.0.0",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/bigquery/prices")
def get_prices(
    days: int = 7,
    api_key: str = Depends(verify_api_key)
):
    """
    Get electricity prices for the last N days
    Safe: Read-only BigQuery query
    """
    logger.info(f"Fetching prices for last {days} days")
    
    query = f"""
    SELECT 
        DATE(settlementDate) as date,
        AVG(price) as avg_price,
        MIN(price) as min_price,
        MAX(price) as max_price,
        COUNT(*) as num_periods
    FROM `{BQ_PROJECT}.{BQ_DATASET}.bmrs_mid`
    WHERE DATE(settlementDate) >= DATE_SUB(CURRENT_DATE(), INTERVAL {days} DAY)
    GROUP BY date
    ORDER BY date DESC
    """
    
    try:
        df = bq_client.query(query).to_dataframe()
        return {
            "success": True,
            "rows": len(df),
            "data": df.to_dict('records')
        }
    except Exception as e:
        logger.error(f"BigQuery error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/bigquery/generation")
def get_generation(
    days: int = 7,
    fuel_type: Optional[str] = None,
    api_key: str = Depends(verify_api_key)
):
    """
    Get generation mix for the last N days
    Safe: Read-only BigQuery query
    """
    logger.info(f"Fetching generation for last {days} days, fuel_type={fuel_type}")
    
    fuel_filter = f"AND fuelType = '{fuel_type}'" if fuel_type else ""
    
    query = f"""
    SELECT 
        DATE(settlementDate) as date,
        fuelType,
        SUM(generation) as total_generation_mw,
        AVG(generation) as avg_generation_mw,
        MAX(generation) as peak_generation_mw
    FROM `{BQ_PROJECT}.{BQ_DATASET}.bmrs_fuelinst`
    WHERE DATE(settlementDate) >= DATE_SUB(CURRENT_DATE(), INTERVAL {days} DAY)
    {fuel_filter}
    GROUP BY date, fuelType
    ORDER BY date DESC, total_generation_mw DESC
    """
    
    try:
        df = bq_client.query(query).to_dataframe()
        return {
            "success": True,
            "rows": len(df),
            "data": df.to_dict('records')
        }
    except Exception as e:
        logger.error(f"BigQuery error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/sheets/read")
def read_sheet(
    tab: str = "Analysis BI Enhanced",
    range: str = "A1:Z100",
    api_key: str = Depends(verify_api_key)
):
    """
    Read data from Google Sheet
    Safe: Read-only access
    """
    logger.info(f"Reading sheet tab '{tab}' range '{range}'")
    
    try:
        gc = get_sheets_client()
        sheet = gc.open_by_key(SHEETS_ID)
        worksheet = sheet.worksheet(tab)
        values = worksheet.get(range)
        
        return {
            "success": True,
            "tab": tab,
            "range": range,
            "rows": len(values),
            "data": values
        }
    except Exception as e:
        logger.error(f"Sheets error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/upcloud/status")
def check_server_status(
    api_key: str = Depends(verify_api_key)
):
    """
    Check UpCloud server status
    Safe: Read-only SSH command
    """
    logger.info("Checking UpCloud server status")
    
    try:
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(UPCLOUD_HOST, username=UPCLOUD_USER, key_filename=UPCLOUD_KEY_PATH)
        
        # Run status check commands
        commands = {
            "arbitrage_service": "systemctl status arbitrage.service --no-pager",
            "disk_usage": "df -h /opt/arbitrage",
            "last_run": "tail -5 /opt/arbitrage/logs/arbitrage.log",
            "health_check": "cat /opt/arbitrage/reports/data/health.json"
        }
        
        results = {}
        for name, cmd in commands.items():
            stdin, stdout, stderr = ssh.exec_command(cmd)
            results[name] = {
                "stdout": stdout.read().decode(),
                "stderr": stderr.read().decode(),
                "exit_code": stdout.channel.recv_exit_status()
            }
        
        ssh.close()
        
        return {
            "success": True,
            "server": UPCLOUD_HOST,
            "timestamp": datetime.utcnow().isoformat(),
            "results": results
        }
    except Exception as e:
        logger.error(f"SSH error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# LEVEL 2: MONITORED WRITE ACCESS (MODERATE)
# ============================================

@app.post("/sheets/update")
def update_sheet(
    tab: str,
    range: str,
    values: list,
    api_key: str = Depends(verify_api_key)
):
    """
    Update Google Sheet with new data
    Moderate risk: Write access with logging
    """
    logger.warning(f"WRITE: Updating sheet tab '{tab}' range '{range}'")
    
    try:
        gc = get_sheets_client()
        sheet = gc.open_by_key(SHEETS_ID)
        worksheet = sheet.worksheet(tab)
        worksheet.update(range, values)
        
        logger.info(f"Successfully updated {len(values)} rows")
        
        return {
            "success": True,
            "tab": tab,
            "range": range,
            "rows_updated": len(values),
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Sheets update error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upcloud/run-script")
def run_approved_script(
    script_name: str,
    api_key: str = Depends(verify_api_key)
):
    """
    Run pre-approved script on UpCloud server
    Moderate risk: Only whitelisted scripts allowed
    """
    # Whitelist of allowed scripts
    ALLOWED_SCRIPTS = [
        "battery_arbitrage.py",
        "update_analysis_bi_enhanced.py",
        "check_health.sh"
    ]
    
    if script_name not in ALLOWED_SCRIPTS:
        logger.warning(f"BLOCKED: Attempted to run unauthorized script: {script_name}")
        raise HTTPException(status_code=403, detail=f"Script '{script_name}' not in whitelist")
    
    logger.warning(f"EXECUTING: Running script '{script_name}' on UpCloud")
    
    try:
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(UPCLOUD_HOST, username=UPCLOUD_USER, key_filename=UPCLOUD_KEY_PATH)
        
        cmd = f"cd /opt/arbitrage && python3 {script_name}"
        stdin, stdout, stderr = ssh.exec_command(cmd)
        
        output = stdout.read().decode()
        error = stderr.read().decode()
        exit_code = stdout.channel.recv_exit_status()
        
        ssh.close()
        
        logger.info(f"Script completed with exit code {exit_code}")
        
        return {
            "success": exit_code == 0,
            "script": script_name,
            "exit_code": exit_code,
            "output": output,
            "error": error,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Script execution error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ============================================
# LEVEL 3: FULL ACCESS (HIGH RISK)
# ============================================

@app.post("/bigquery/execute")
def execute_bigquery(
    query: str,
    dry_run: bool = True,
    api_key: str = Depends(verify_api_key)
):
    """
    Execute arbitrary BigQuery query
    HIGH RISK: Can modify/delete data
    Default: dry_run=True for safety
    """
    logger.warning(f"BIGQUERY EXECUTE (dry_run={dry_run}): {query[:100]}...")
    
    if not dry_run:
        logger.critical("DANGEROUS: Executing WRITE query on BigQuery!")
    
    try:
        job_config = bigquery.QueryJobConfig(dry_run=dry_run)
        query_job = bq_client.query(query, job_config=job_config)
        
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "bytes_processed": query_job.total_bytes_processed,
                "estimated_cost_usd": (query_job.total_bytes_processed / 1e12) * 5,
                "query": query
            }
        else:
            df = query_job.to_dataframe()
            return {
                "success": True,
                "dry_run": False,
                "rows_affected": len(df),
                "data": df.to_dict('records')
            }
    except Exception as e:
        logger.error(f"BigQuery execution error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/upcloud/ssh")
def execute_ssh_command(
    command: str,
    require_approval: bool = True,
    api_key: str = Depends(verify_api_key)
):
    """
    Execute arbitrary SSH command on UpCloud
    HIGH RISK: Full shell access
    Default: require_approval=True
    """
    logger.critical(f"SSH COMMAND REQUEST: {command}")
    
    # Dangerous command detection
    DANGEROUS_KEYWORDS = ['rm -rf', 'dd if=', 'mkfs', ':(){:|:&};:', 'chmod 777', 'wget | sh']
    if any(keyword in command.lower() for keyword in DANGEROUS_KEYWORDS):
        logger.critical(f"BLOCKED DANGEROUS COMMAND: {command}")
        raise HTTPException(status_code=403, detail="Dangerous command blocked")
    
    if require_approval:
        logger.warning("Approval required - returning preview only")
        return {
            "success": False,
            "approval_required": True,
            "command": command,
            "message": "This command requires manual approval. Set require_approval=false to execute."
        }
    
    logger.critical(f"EXECUTING COMMAND: {command}")
    
    try:
        ssh = paramiko.SSHClient()
        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        ssh.connect(UPCLOUD_HOST, username=UPCLOUD_USER, key_filename=UPCLOUD_KEY_PATH)
        
        stdin, stdout, stderr = ssh.exec_command(command)
        
        output = stdout.read().decode()
        error = stderr.read().decode()
        exit_code = stdout.channel.recv_exit_status()
        
        ssh.close()
        
        return {
            "success": exit_code == 0,
            "command": command,
            "exit_code": exit_code,
            "output": output,
            "error": error,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"SSH execution error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("ðŸš€ Starting Power Market AI Gateway")
    print(f"ðŸ“ Logs: /tmp/ai-gateway.log")
    print(f"ðŸ”’ API Key required for all endpoints")
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## **Step 2: Deploy the API Gateway**

### **Option A: Run on Your Mac (Development)**

```bash
# Install dependencies
pip install fastapi uvicorn google-cloud-bigquery gspread oauth2client paramiko

# Set API key
export AI_GATEWAY_API_KEY="your-super-secure-random-key-here"

# Run server
python api_gateway.py

# Server runs at: http://localhost:8000
```

### **Option B: Run on UpCloud (Production)**

```bash
# Upload to UpCloud
scp api_gateway.py root@94.237.55.15:/opt/arbitrage/

# SSH into server
ssh root@94.237.55.15

# Install dependencies
cd /opt/arbitrage
pip install fastapi uvicorn google-cloud-bigquery gspread oauth2client paramiko

# Set API key
echo 'export AI_GATEWAY_API_KEY="your-super-secure-random-key-here"' >> ~/.bashrc
source ~/.bashrc

# Run with nohup (background)
nohup uvicorn api_gateway:app --host 0.0.0.0 --port 8000 >> logs/api-gateway.log 2>&1 &

# Or create systemd service (recommended)
cat > /etc/systemd/system/ai-gateway.service << 'EOF'
[Unit]
Description=AI Gateway API
After=network.target

[Service]
Type=simple
User=root
WorkingDirectory=/opt/arbitrage
Environment="AI_GATEWAY_API_KEY=your-super-secure-random-key-here"
ExecStart=/usr/local/bin/uvicorn api_gateway:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable ai-gateway
systemctl start ai-gateway
systemctl status ai-gateway
```

---

## **Step 3: Test the API**

```bash
# Set your API key
API_KEY="your-super-secure-random-key-here"
API_URL="http://localhost:8000"  # or http://94.237.55.15:8000

# Test health check
curl $API_URL/

# Test BigQuery prices (read-only, safe)
curl -H "Authorization: Bearer $API_KEY" \
  "$API_URL/bigquery/prices?days=7"

# Test generation data
curl -H "Authorization: Bearer $API_KEY" \
  "$API_URL/bigquery/generation?days=14&fuel_type=WIND"

# Test Google Sheets read
curl -H "Authorization: Bearer $API_KEY" \
  "$API_URL/sheets/read?tab=Analysis%20BI%20Enhanced&range=A1:E10"

# Test UpCloud status
curl -H "Authorization: Bearer $API_KEY" \
  "$API_URL/upcloud/status"

# Test sheet update (WRITE operation)
curl -X POST -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"tab": "Raw Data", "range": "A1", "values": [["Updated by AI", "2025-11-06"]]}' \
  "$API_URL/sheets/update"

# Test approved script execution
curl -X POST -H "Authorization: Bearer $API_KEY" \
  "$API_URL/upcloud/run-script?script_name=battery_arbitrage.py"
```

---

## **Step 4: Create ChatGPT Action**

### **4.1: Create OpenAPI Schema**

```yaml
# File: openapi.yaml
openapi: 3.0.0
info:
  title: Power Market AI Gateway
  version: 1.0.0
  description: API for AI to interact with GB power market infrastructure

servers:
  - url: http://94.237.55.15:8000
    description: Production server

security:
  - BearerAuth: []

paths:
  /bigquery/prices:
    get:
      summary: Get electricity prices
      operationId: getPrices
      parameters:
        - name: days
          in: query
          schema:
            type: integer
            default: 7
      responses:
        '200':
          description: Successful response

  /bigquery/generation:
    get:
      summary: Get generation mix data
      operationId: getGeneration
      parameters:
        - name: days
          in: query
          schema:
            type: integer
        - name: fuel_type
          in: query
          schema:
            type: string
      responses:
        '200':
          description: Successful response

  /upcloud/status:
    get:
      summary: Check UpCloud server status
      operationId: getServerStatus
      responses:
        '200':
          description: Server status

components:
  securitySchemes:
    BearerAuth:
      type: http
      scheme: bearer
```

### **4.2: Configure in ChatGPT**

1. Go to ChatGPT â†’ Settings â†’ Actions
2. Click "Create new action"
3. Upload `openapi.yaml`
4. Set authentication:
   - Type: Bearer Token
   - Token: `your-super-secure-random-key-here`
5. Test the action
6. Save and enable

### **4.3: Example ChatGPT Conversation**

```
You: "What were the electricity prices yesterday?"

ChatGPT: [Calls /bigquery/prices endpoint]
  "Yesterday's electricity prices:
   - Average: Â£52.30/MWh
   - Peak: Â£120.50/MWh at 18:00
   - Minimum: Â£12.80/MWh at 03:00
   - Negative price periods: 0"

You: "How much wind generation did we have?"

ChatGPT: [Calls /bigquery/generation?fuel_type=WIND]
  "Wind generation yesterday:
   - Total: 280,500 MWh
   - Average: 11,687 MW
   - Peak: 14,230 MW at 14:30
   - This represents 32% of total generation"

You: "Check if my server is running ok"

ChatGPT: [Calls /upcloud/status]
  "Your UpCloud server is healthy:
   âœ… Arbitrage service: Active (running)
   âœ… Last run: 2025-11-06 04:00 UTC
   âœ… Disk usage: 23% (34GB free)
   âœ… Health check: All systems operational"
```

---

## ðŸ”’ Security Considerations

### **Critical Security Measures**:

1. **API Key Protection**
   ```bash
   # Generate strong random key
   openssl rand -hex 32
   
   # Store in environment variable (never in code)
   export AI_GATEWAY_API_KEY="your-generated-key"
   ```

2. **Rate Limiting**
   ```python
   from slowapi import Limiter
   from slowapi.util import get_remote_address
   
   limiter = Limiter(key_func=get_remote_address)
   app.state.limiter = limiter
   
   @app.get("/bigquery/prices")
   @limiter.limit("10/minute")  # Max 10 requests per minute
   def get_prices(...):
       ...
   ```

3. **IP Whitelisting**
   ```python
   ALLOWED_IPS = ["YOUR_IP", "OPENAI_IP_RANGE"]
   
   @app.middleware("http")
   async def ip_filter(request: Request, call_next):
       client_ip = request.client.host
       if client_ip not in ALLOWED_IPS:
           return JSONResponse(status_code=403, content={"detail": "IP not allowed"})
       return await call_next(request)
   ```

4. **HTTPS/SSL** (Production)
   ```bash
   # Get Let's Encrypt certificate
   certbot certonly --standalone -d your-domain.com
   
   # Run with SSL
   uvicorn api_gateway:app --host 0.0.0.0 --port 443 \
     --ssl-keyfile=/etc/letsencrypt/live/your-domain.com/privkey.pem \
     --ssl-certfile=/etc/letsencrypt/live/your-domain.com/fullchain.pem
   ```

5. **Audit Logging**
   ```python
   # All actions logged to file
   import logging
   logging.basicConfig(
       filename='/var/log/ai-gateway-audit.log',
       level=logging.INFO,
       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
   )
   ```

---

## ðŸ“Š Monitoring & Alerts

### **Slack Notifications**

```python
import requests

def send_slack_alert(message, level="info"):
    """Send alert to Slack"""
    webhook_url = os.environ.get("SLACK_WEBHOOK_URL")
    
    emoji = {"info": "â„¹ï¸", "warning": "âš ï¸", "critical": "ðŸš¨"}
    
    requests.post(webhook_url, json={
        "text": f"{emoji.get(level, 'â„¹ï¸')} {message}"
    })

# Use in endpoints
@app.post("/upcloud/ssh")
def execute_ssh_command(command: str, ...):
    send_slack_alert(f"SSH command executed: {command}", level="warning")
    ...
```

---

## ðŸŽ¯ Recommended Rollout Plan

### **Phase 1: Read-Only (Week 1)**
1. âœ… Deploy API gateway on your Mac
2. âœ… Enable read-only endpoints
3. âœ… Test with curl commands
4. âœ… Monitor logs for issues

### **Phase 2: ChatGPT Integration (Week 2)**
5. âœ… Create OpenAPI schema
6. âœ… Configure ChatGPT Action
7. âœ… Test with read-only queries
8. âœ… Verify security and logging

### **Phase 3: Write Access (Week 3)**
9. âš ï¸ Enable sheet update endpoint
10. âš ï¸ Enable approved script execution
11. âš ï¸ Add Slack alerts
12. âš ï¸ Test with small updates

### **Phase 4: Production (Week 4)**
13. ðŸš€ Move to UpCloud server
14. ðŸš€ Add SSL/HTTPS
15. ðŸš€ Enable full automation
16. ðŸš€ Monitor and optimize

---

## ðŸ’¡ Use Cases

### **1. Real-Time Data Analysis**
```
You: "Compare today's wind generation to last week"
ChatGPT: [Queries BigQuery automatically]
Result: Instant analysis with charts
```

### **2. Automated Reporting**
```
You: "Update the dashboard with latest prices"
ChatGPT: [Calls sheet update API]
Result: Google Sheet updated automatically
```

### **3. Server Management**
```
You: "Is my arbitrage script running? If not, restart it"
ChatGPT: [Checks status, runs script if needed]
Result: Self-healing automation
```

### **4. Proactive Alerts**
```
ChatGPT: [Monitors prices every hour]
          "âš¡ Alert: Price dropped to -Â£5/MWh at 14:00"
You: "Thanks! Show me the full day's data"
ChatGPT: [Provides detailed breakdown]
```

---

## ðŸ“š Related Documentation

- **AI_INTEGRATION_GUIDE.md** - How ChatGPT currently works
- **MASTER_SYSTEM_DOCUMENTATION.md** - Complete system overview
- **PRODUCTION_READY.md** - Current production setup

---

## âš ï¸ Final Warning

This setup gives AI assistants **real power** over your infrastructure. Recommendations:

1. âœ… Start with read-only access
2. âœ… Add comprehensive logging
3. âœ… Set up alerts for all write operations
4. âœ… Use strong authentication
5. âœ… Enable rate limiting
6. âœ… Test thoroughly before production
7. âš ï¸ Never expose without authentication
8. âš ï¸ Monitor costs (BigQuery, API calls)
9. âš ï¸ Have rollback procedures ready
10. ðŸ”’ Use HTTPS in production

**Remember**: With great power comes great responsibility! ðŸ¦¸

---

*Last Updated: 2025-11-06*  
*Status: Setup guide - not yet implemented*
